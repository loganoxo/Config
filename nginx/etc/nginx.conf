# nginx                             启动 Nginx 服务,如果 Nginx 已经在运行,执行该命令会启动一个新的工作进程
# nginx -c /path/to/nginx.conf      使用指定的配置文件启动 Nginx,而不是默认的 /etc/nginx/nginx.conf
# nginx -s stop                     停止 Nginx 服务,强制退出所有 worker 进程
# nginx -t                          检查 Nginx 配置文件的语法是否正确
# nginx -s reload                   重载配置文件
# nginx -v                          显示当前安装的 Nginx 版本
# nginx -V                          显示详细的 Nginx 编译时选项,包括编译时使用的模块和编译参数

# Nginx 并不是传统意义上的多线程模型, 而是基于事件驱动（event-driven）的单线程非阻塞 I/O模型; 具体来说：
#       1、每个 worker process 是单线程的，处理所有的请求
#       2、一个线程可以处理多个连接，依靠事件循环机制(如 epoll、kqueue)高效管理大量并发请求, 这种方式极大地减少了线程切换和内存消耗
#       3、worker_connections 定义了一个 worker process 能够处理的最大连接数，但这不代表每个连接会有一个独立线程
#       4、总并发数 = worker_processes × worker_connections

# 每当进程打开一个文件、网络连接或其他 I/O 资源时, 操作系统会分配一个文件描述符来标识该资源, 以便进程可以进行相应的读写操作
# 文件描述符是操作系统与进程之间的桥梁, 进程通过文件描述符来访问文件、设备、管道、套接字等资源, 每个文件描述符代表一个打开的资源
# 操作系统对单个进程的文件描述符数量设限, 为了防止资源耗尽, 避免单个进程占用过多内存,
# 操作系统本身有一个全局文件描述符限制, 表示系统中所有进程可以同时打开的最大文件描述符数量;
# 这个限制通常可以通过以下命令查看: cat /proc/sys/fs/file-max
# ulimit -n 查看 mac 和 linux 的系统 针对于单个进程的 最大文件描述符的限制
# ulimit -n <number> 临时修改当前shell 的进程的最大描述符
worker_rlimit_nofile 4096; #通过nginx设置对于每个nginx工作进程的最大描述符, 相当于执行了 ulimit -n <number>

# 运行用户
# user  nginx;
# 启动工作进程数; auto: 会设置成cpu的核心数
worker_processes  auto;
# 工作模式及连接数上限
events    {
    # 单个后台worker process进程的最大并发链接数,不能大于系统针对于单个进程的文件描述符的限制; mac上最大256; 如果超出, nginx -t 会有警告
    # 通过 worker_rlimit_nofile 使用提高这个限制;
    # 反向代理场景: 每个客户端连接通常需要2个文件描述符(一个用于客户端到Nginx，另一个用于Nginx到后端服务器)
    # 其他因素: 日志文件、配置文件、SSL/TLS操作等可能需要额外文件描述符,建议预留余量
    # worker_rlimit_nofile >= worker_connections * 2 + 余量
    worker_connections  1024;

    # 每个 worker_process 进程会通过 accept 系统调用来接收客户端的连接;
    # 默认情况下, worker_process 会在事件循环中反复调用 accept, 每次只接受一个连接并进行处理; 即使有多个连接等待接受, worker_process 会继续轮询直到接受完所有的连接
    # 当 multi_accept 设置为 on 时, Nginx 的工作进程在每次调用 accept 时, 可以一次性接受多个连接;
    # 这样可以减少每次 accept 调用的时间间隔, 降低 worker 进程空闲等待的时间, 提高处理连接的效率
    # 然而，使用 multi_accept 也有一个副作用, 即可能会增加每次 accept 调用后连接的数量,导致每个连接的处理可能会稍微延迟,因为 worker_process 需要处理更多的连接
    # 当有大量连接需要同时处理时(比如网站流量激增,或者有大量并发连接时),启用 multi_accept 可以有效提高 Nginx 处理连接的能力
    multi_accept on;

    # 默认nginx会自动根据操作系统自动选择最优事件模型, Linux -> epoll; BSD/macOS-> kqueue(不支持aio); 其他系统 -> select 或 poll(性能较差)
    # use epoll;                # 手动设置使用高效的事件模型(如 epoll),mac不支持
}

# 日志等级: debug, info, notice, warn, error, crit, alert, emerg, 设置为某个级别后, 会记录这个级别以及更严重的级别的日志
error_log  /Users/logan/Logs/nginx/error.log;               #默认的error级别,只记录错误信息及更高级别的信息
#error_log  /Users/logan/Logs/nginx/notice.log  notice;      #记录的是较为普通的运行信息,记录一些常规事件和系统状态
error_log  /Users/logan/Logs/nginx/info.log  info;          #记录较为详细的信息,比 notice 级别更为详细,适合于调试和监控
#error_log  /Users/logan/Logs/nginx/debug.log  debug;        #要进行debug起作用,需要使用--with-debug构建nginx

pid        /Users/logan/Logs/nginx/nginx.pid;

http    {
    #设定mime类型(邮件支持类型),类型由mime.types文件定义
    include       mime.types;
    default_type  application/octet-stream;

    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for" '
                    '"$http_origin" "$scheme://$http_host$request_uri" ';

    log_format json_escape '{
    "remote_addr":"$remote_addr",
    "remote_user":"$remote_user",
    "time_local":"$time_local",
    "request":"$request",
    "status":"$status",
    "body_bytes_sent":"$body_bytes_sent",
    "http_referer":"$http_referer",
    "http_user_agent":"$http_user_agent",
    "http_x_forwarded_for":"$http_x_forwarded_for",
    "http_origin":"$http_origin",
    "URL":"$scheme://$http_host$request_uri"
}
';

    # 应用日志格式到访问日志文件
    access_log /Users/logan/Logs/nginx/access_main.log main;
    # tail -f /Users/logan/Logs/nginx/access_json.log | jq
    access_log /Users/logan/Logs/nginx/access_json.json json_escape;

    sendfile        on; #见file_server_nginx.conf
    #tcp_nopush     on; #见file_server_nginx.conf

    # 设置 HTTP 长连接 的 空闲超时时间, HTTP 协议默认使用 TCP 连接,传统的 HTTP/1.0 每次请求响应后会关闭连接
    # 在 HTTP/1.1 中，引入了 长连接(Keep-Alive),允许多个 HTTP 请求和响应复用同一个 TCP 连接,从而减少连接建立和关闭的开销(如三次握手/四次挥手)
    # 设置一个连接在空闲状态下保持的时间,如果在指定时间内没有新的请求,这个连接会被关闭,主要用于防止空闲连接长时间占用服务器资源
    keepalive_timeout  65s;      #默认为75s

    # 启用 Gzip 压缩, 默认为off;这意味着所有符合条件的响应(如文本文件)将被压缩后发送给客户端,从而减少传输的数据量,提高网站加载速度
    gzip on;
    # 设置触发压缩的最小文件大小,默认为20(字节),实际长度为响应头的Content-Length指定
    gzip_min_length 1k;
    # 默认为1.1; 设置压缩响应所需的请求的最小HTTP版本; 只有在客户端使用的 HTTP 版本高于这个版本时,Nginx 才会发送压缩响应
    gzip_http_version 1.1;

    # 默认为1;设置响应的GZIP压缩level;可接受的值在1(最低压缩率) 到 9(最高压缩率)
    gzip_comp_level 4;

    # 默认仅为text/html; 指定需要压缩的 MIME 类型; 避免对已压缩格式(如 JPEG、PNG)启用 GZIP
    # text/javascript 已被 application/javascript 取代; text/xml 已被 application/xml 取代
    gzip_types text/html text/plain text/css application/javascript application/json application/xml;

    # 默认为off; 开启后,在响应头中添加 Vary: Accept-Encoding;通知缓存系统(如 CDN、代理服务器、浏览器)该响应可能因Accept-Encoding不同而变化
    # 缓存服务会根据响应中的Vary头, 将请求头中的Accept-Encoding的值纳入缓存键;
    # 如: 请求头Accept-Encoding: gzip -> 缓存键包含gzip; 请求头Accept-Encoding: br -> 缓存键包含br;
    # 同一URL会根据不同的Accept-Encoding存储多个版本; 二次请求时就通过客户端请求头中的 Accept-Encoding的值, 去命中缓存
    # 若未添加此头,缓存可能错误地将缓存中的 压缩后的响应 返回给 不支持解压的客户端(如某些旧浏览器),导致内容无法解析
    gzip_vary on;

    ####################################################################################
    server    {
        listen 18080;
        server_name  localhost;
        charset utf-8;
        default_type text/plain;

        # 针对这个server单独设置日志,会导致在 http模块 中统一设置的日志中 不记录这个server
        # access_log /Users/logan/Logs/nginx/18080_log.json json_escape;

        location /    {
            #确定根目录,html是相对于nginx的执行文件的目录;即/opt/homebrew/Cellar/nginx/1.27.3/html;这个目录被homebrew软链接到/opt/homebrew/var/www,我又把Data/Config/nginx/www软链接到了这个目录,所以这里的html实际上就是www
            root   html;
            index  index.html index.htm;
        }

        #error_page  404              /404.html;

        # redirect server error pages to the static page /50x.html
        error_page   500 502 503 504  /50x.html;
        location = /50x.html    {
            root   html;
        }
    }
    include servers/*.conf;
}
